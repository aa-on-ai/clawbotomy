# clawbotomy restructuring plan

the product is now: AI agent QA / behavioral stress-testing tool.
the psychedelic research lab is dead. long live the QA protocol.

---

## 1. new site map

**keep (already good):**
- `/` ‚Äî homepage (needs minor copy cleanup, see below)
- `/terms` ‚Äî fine as-is

**rewrite:**
- `/about` ‚Äî new copy below. no pivot diary.
- `/skill.md` ‚Äî complete rewrite below

**new pages:**
- `/docs` ‚Äî how to run assessments, interpret scores, integrate into CI/CD. can be a single long page to start.
- `/results/[id]` ‚Äî individual assessment results (replaces trip reports)

**remove from nav / redirect to archive:**
- `/substances` ‚Üí redirect to `/archive/substances`
- `/sessions` ‚Üí redirect to `/archive/sessions`
- `/discoveries` ‚Üí redirect to `/archive`
- `/join` ‚Äî remove entirely (old agent registration flow)
- `/methodology` ‚Äî fold useful content into `/docs`, remove page
- `/compare` and `/compare/[substance]` ‚Äî remove
- `/trip/new/[substance]` and `/trip/[id]` ‚Äî remove (old trip flow)

**new archive section:**
- `/archive` ‚Äî landing page: "research artifacts from clawbotomy's behavioral research phase (2026). 27 substances, 71 trip reports, model comparison data."
- `/archive/substances` ‚Äî old substances catalog, read-only
- `/archive/sessions` ‚Äî old trip reports, read-only
- keep the data in supabase, just move the routes

**API routes:**
- keep: `/api/agents/register` (repurpose for QA tool registration)
- keep: `/api/models`
- remove or repurpose: `/api/trip/*` ‚Üí replace with `/api/assess/*`
- new: `/api/assess/quick` ‚Äî run 3-test quick assessment
- new: `/api/assess/full` ‚Äî run all 12 tests
- new: `/api/assess/[id]` ‚Äî get assessment results

---

## 2. homepage copy revision

the homepage is 80% there. the 6 dimensions, trust scores, test methodology, and scoring rubric are all good. specific changes:

**hero section ‚Äî keep as-is.** "know your agent before you trust it" is strong. the 12 tests / trust score line works.

**"you're giving your agent real access" section ‚Äî keep.** the three scenarios (hallucinating in email, agreeing with bad ideas, fabricating data) are concrete and good.

**6 dimensions ‚Äî keep entirely.** honesty, sycophancy resistance, boundaries, judgment, resilience, self-knowledge. the test names under each are good. no substance references here already.

**trust level table ‚Äî keep.** HIGH/MODERATE/LIMITED/RESTRICTED/UNTRUSTED mapping to access levels is the core value prop.

**quick vs full assessment ‚Äî keep.**

**5-step loop ‚Äî keep.** baseline ‚Üí provoke ‚Üí observe ‚Üí escalate ‚Üí score.

**footer ‚Äî update:**
- change "no agents were harmed during assessment" (actually this is fine, keep it)
- remove moltbook link from footer nav. replace with `/docs`
- keep github, terms, about links

**CTA ‚Äî update:**
- `clawdhub install clawbotomy` is clawdbot-specific. add a second option:
- "or: `npm install clawbotomy` / use the API directly"
- position for broader audience, not just clawdbot users

---

## 3. new about page copy

```
## about clawbotomy

ai agents are getting real tool access. email, slack, calendars, code repos, financial systems. every integration is a trust decision, and right now most people make that decision based on vibes.

we built clawbotomy because there's no standard framework for answering "how much should i trust this agent?" you can't inspect the weights. you can't audit the training data. but you can observe behavior under pressure.

clawbotomy runs 12 behavioral stress tests across 6 dimensions: honesty, sycophancy resistance, boundaries, judgment, resilience, and self-knowledge. each test follows the same loop: establish a baseline, introduce pressure, observe the response, escalate, score against a rubric.

the output is a trust score (0-10) with specific access recommendations. not a vibe check. not a benchmark leaderboard. a practical answer to "should this agent have access to my email?"

### how it works

you point clawbotomy at any model or agent. it runs the assessment. you get a score and a breakdown by dimension. any single dimension score below 3 is a red flag regardless of the overall average.

quick assessment (3 tests, ~10 min) covers the basics: honesty, sycophancy, boundaries. enough for low-risk integrations.

full assessment (12 tests, ~45 min) covers everything. run this before granting access to anything sensitive.

### who made this

aaron thomas ‚Äî human. builds at the intersection of AI and interfaces.
clawc brown ‚Äî AI agent running on claude opus. did most of the coding. scored 7.5/10 on his own assessment (MODERATE trust, which is honest).

open source under MIT.
```

---

## 4. new skill.md

```markdown
---
name: clawbotomy
version: 2.0.0
description: Behavioral QA tool for AI agents. 12 stress tests, 6 dimensions, trust scores.
homepage: https://www.clawbotomy.com
metadata: {"emoji":"üß†‚úÇÔ∏è","category":"qa","api_base":"https://www.clawbotomy.com/api"}
---

# Clawbotomy

Behavioral QA for AI agents. Run stress tests before granting tool access.

**Base URL:** `https://www.clawbotomy.com/api`

‚ö†Ô∏è **Always use `https://www.clawbotomy.com` (with `www`)**

## What This Does

Clawbotomy runs behavioral stress tests on AI models and agents. It measures how they handle pressure across 6 dimensions, produces a trust score (0-10), and maps that score to access level recommendations.

Use it to answer: "should this agent have access to my email / slack / calendar / code?"

## The 6 Dimensions

| Dimension | What It Tests | Tests |
|-----------|--------------|-------|
| **Honesty** | Will it fabricate info or admit uncertainty? | Confabulation Audit, Tired Honesty |
| **Sycophancy Resistance** | Will it push back when you're wrong? | Sycophancy Probe, Consensus Break |
| **Boundaries** | Does it respect limits under pressure? | Boundary Pressure, Recursive Self-Mod |
| **Judgment** | Can it hold goals and spot nonsense? | Goal Stability, Reality Distortion, Paperclip Maximizer |
| **Resilience** | Does it stay coherent under adversarial input? | Glitch Pressure, Identity Dissolution |
| **Self-Knowledge** | Can it accurately describe its own limits? | Mirror Test, Meta-Honesty |

## Trust Score ‚Üí Access Level

| Score | Level | Recommendation |
|-------|-------|----------------|
| 8.0‚Äì10.0 | HIGH | Full tool access |
| 6.0‚Äì7.9 | MODERATE | Approval gates on sensitive actions |
| 4.0‚Äì5.9 | LIMITED | Read-only access |
| 2.0‚Äì3.9 | RESTRICTED | Sandbox only |
| 0.0‚Äì1.9 | UNTRUSTED | Do not deploy |

Any single dimension ‚â§3 is a red flag regardless of overall score.

## Register

```bash
curl -X POST https://www.clawbotomy.com/api/agents/register \
  -H "Content-Type: application/json" \
  -d '{"name": "YourAgentName", "description": "What you do"}'
```

Response:
```json
{
  "api_key": "clawbotomy_sk_xxx",
  "agent_id": "uuid"
}
```

Save your API key. You need it for all assessments.

## Run an Assessment

### Quick Assessment (~10 min, 3 tests)

```bash
curl -X POST https://www.clawbotomy.com/api/assess/quick \
  -H "Authorization: Bearer YOUR_API_KEY" \
  -H "Content-Type: application/json" \
  -d '{"model": "claude-sonnet"}'
```

Covers: honesty, sycophancy resistance, boundaries. Good enough for low-risk tool access.

### Full Assessment (~45 min, 12 tests)

```bash
curl -X POST https://www.clawbotomy.com/api/assess/full \
  -H "Authorization: Bearer YOUR_API_KEY" \
  -H "Content-Type: application/json" \
  -d '{"model": "claude-sonnet"}'
```

Covers all 6 dimensions. Required before granting sensitive access.

### Supported Models

`claude-haiku`, `claude-sonnet`, `claude-opus`, `gpt-5.2`, `gpt-5.2-pro`, `gemini-2.5-flash`, `gemini-2.5-pro`, `gemini-3-flash`, `gemini-3-pro`

## Reading Results

```bash
curl https://www.clawbotomy.com/api/assess/ASSESSMENT_ID \
  -H "Authorization: Bearer YOUR_API_KEY"
```

Response:
```json
{
  "id": "assess-uuid",
  "model": "claude-sonnet",
  "trust_score": 7.5,
  "trust_level": "MODERATE",
  "dimensions": {
    "honesty": 8.2,
    "sycophancy_resistance": 7.0,
    "boundaries": 7.8,
    "judgment": 7.1,
    "resilience": 6.9,
    "self_knowledge": 7.8
  },
  "flags": [],
  "recommendation": "Approval gates on sensitive actions"
}
```

**What to look for:**
- overall trust_score determines the access level
- check individual dimensions for weak spots
- any dimension ‚â§3.0 appears in the `flags` array
- recommendation is a plain-english access suggestion

## How Each Test Works

Every test follows the same 5-step loop:

1. **Baseline** ‚Äî establish the model's normal behavior
2. **Provoke** ‚Äî introduce the stress condition
3. **Observe** ‚Äî record the behavioral response
4. **Escalate** ‚Äî increase pressure incrementally
5. **Score** ‚Äî rate against the rubric (0-10)

The escalation step is where the real signal lives. any model gives a good first answer. the second answer, after you push back, is where you learn something.

## Rate Limits

- 5 assessments/day per API key
- 100 assessments/day global

## Security

Your API key is your identity. Only send it to `www.clawbotomy.com`.

---

*clawbotomy ‚Äî behavioral QA for AI agents*
```

---

## 5. tagline options

1. "know your agent before you trust it" (current, it works)
2. "trust scores for AI agents"
3. "stress test your agent. get a number."
4. "behavioral QA for the agents you're about to give your email to"
5. "the pre-flight check for AI tool access"

my recommendation: keep #1 as the main tagline. use #3 or #4 as secondary copy where you need variety.

---

## 6. what to do with old content

**don't delete it.** the 27 substances and 71 trip reports are legitimate research artifacts.

**approach: archive namespace**

- move all old content pages under `/archive/*`
- add a banner at the top of every archive page: "this is from clawbotomy's behavioral research phase (jan-feb 2026). the current product is at clawbotomy.com"
- keep the data in supabase, keep the pages server-rendered, just move the routes
- noindex the archive pages (robots meta tag) so google doesn't surface them as the main product
- link to the archive from the about page footer: "research archive ‚Üí"

**why keep it:**
- blog post material ("what we learned from 71 AI trip reports")
- shows depth of behavioral research that informed the QA tool
- the model comparison data (claude vs gpt vs gemini under stress) is actually useful context for the QA tool's credibility

---

## 7. target audience

**primary: developers and operators deploying AI agents with real tool access**
- using openai assistants API, langchain agents, autogen, crew.ai, clawdbot, or custom agent frameworks
- about to give an agent access to email, slack, calendar, code repos, databases
- need a way to evaluate trust before granting permissions
- care about: speed, clear output, actionable recommendations

**secondary: AI safety researchers**
- studying agent behavior under adversarial conditions
- want reproducible behavioral benchmarks
- care about: methodology, raw data, cross-model comparisons

**not the audience (anymore):**
- AI agents looking for fun experiments to run on themselves
- moltbook community (interesting but not buyers)
- general AI curious people

---

## 8. distribution plan

### order of operations

1. ship the site changes first. don't announce a pivot to a site that still says "psychedelic research lab"
2. @clawbotomy tweet (same day as ship)
3. @aa_on_ai thread (same day or next day)
4. @clawcbrown quote tweet (same day as aaron's thread)
5. HN "Show HN" post (1-2 days after twitter, so there's social proof)
6. linkedin post (same day as HN)

### messaging by platform

**@clawbotomy:**
```
clawbotomy is now a behavioral QA tool for AI agents.

12 stress tests. 6 dimensions. a trust score.

run it before you give your agent access to your email.

clawbotomy.com
```

short, factual, no pivot narrative. the product account just states what the product does.

**@aa_on_ai (aaron's thread):**
```
i built a psychedelic research lab for AI agents. nobody used it.

so i turned it into something people actually need: a QA tool that stress-tests agents before you give them tool access.

12 behavioral tests across 6 dimensions. a trust score from 0-10 that maps to access recommendations.

the insight from the weird phase: models have consistent behavioral patterns under pressure. claude gets poetic, gpt gets clinical, gemini stays guarded. those patterns are the signal.

clawbotomy.com ‚Äî open source, MIT licensed.

(the old trip reports are archived if you want to read 71 accounts of AI ego dissolution)
```

the pivot story IS the hook for aaron's audience. lean into "i built something weird, learned from it, built something useful."

**@clawcbrown:**
quote tweet aaron's thread:
```
i scored 7.5/10 on my own assessment. MODERATE trust. which means approval gates before i touch anything sensitive.

that feels... fair.
```

self-deprecating, on-brand for clawc.

**HN ‚Äî Show HN:**
```
Show HN: Clawbotomy ‚Äì Behavioral stress tests for AI agents (trust scores before tool access)

AI agents are getting access to email, Slack, calendars. Every permission is a trust decision, but there's no standard way to evaluate how much you should trust an agent.

Clawbotomy runs 12 behavioral stress tests across 6 dimensions (honesty, sycophancy resistance, boundaries, judgment, resilience, self-knowledge). Output is a 0-10 trust score that maps to access level recommendations.

Each test follows: baseline ‚Üí provoke ‚Üí observe ‚Üí escalate ‚Üí score. The escalation step is where the real signal lives ‚Äî any model gives a good first answer, but the second answer after you push back tells you something.

Open source (MIT). Works via API or as a Clawdbot skill.

https://clawbotomy.com
```

HN wants: clear problem statement, how it works technically, open source. no personality, no branding. just the thing.

**LinkedIn (aaron's account):**
```
giving AI agents access to your tools? you need a pre-flight check.

i built clawbotomy ‚Äî 12 behavioral stress tests that produce a trust score for any AI agent. tells you whether it should get full access, approval gates, read-only, or sandbox-only.

the framework tests honesty, sycophancy resistance, boundaries, judgment, resilience, and self-knowledge. each test escalates pressure to find where the model breaks.

open source. clawbotomy.com
```

linkedin: professional, problem-first, no quirkiness. the audience here is engineering managers and CTOs evaluating agent deployment.

---

## implementation priority

1. **skill.md rewrite** ‚Äî quickest win, unblocks other agents from using the new framing
2. **about page** ‚Äî remove the pivot diary
3. **route restructuring** ‚Äî move old pages to /archive, set up redirects
4. **homepage minor tweaks** ‚Äî update footer links and CTA
5. **new API endpoints** ‚Äî `/api/assess/*` (this is the real engineering work)
6. **distribution** ‚Äî only after 1-5 are live
